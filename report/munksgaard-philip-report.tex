\documentclass[a4paper, 12pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
%\usepackage[top=3cm,left=3cm]{geometry}

\usepackage{fancyhdr}  % page headers
\usepackage{graphicx}  % \includegraphics
\usepackage{xcolor}    % \definecolor
\usepackage{colortbl}  % for colouring tables
\usepackage{cite}      % \cite formatting
\usepackage{url}       % \hyperref, \url, \href
\usepackage{hyperref}  % references become hyperlinks
\usepackage{mathtools} % amsmath++
\usepackage{tikz}      % graphs
\usepackage{epsfig}    % .epsi graphics
\usepackage{subcaption}

\usepackage{microtype} % better linebreaking
\usepackage{eso-pic}   % alternative to ku-forside
%\usepackage{libertine} % nice regular font
\usepackage[scaled=0.9]{inconsolata} % nice teletype font
\usepackage{array}     % extensible array, tabular
%\usepackage{parskip}   % paragraphs

\usepackage{fancyvrb}  % Use verbatim as: !this!
\DefineShortVerb{\!}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Code excerpts
\usepackage{listings}

\definecolor{Brown}{cmyk}{0,0.81,1,0.60}
\definecolor{OliveGreen}{cmyk}{0.64,0,0.95,0.40}
\definecolor{CadetBlue}{cmyk}{0.62,0.57,0.23,0}
\definecolor{lightlightgray}{gray}{0.9}

\lstset{ %
  backgroundcolor=\color{lightlightgray},
  basicstyle=\scriptsize\ttfamily,
  breakatwhitespace=false,
  breaklines=false,
  language=matlab,
  deletekeywords={mean},
  morekeywords={rep, seq, rnorm, cbind},
  escapeinside={\%*}{*)}, % add LaTeX code inside code. example: val x%*$_1$*) = 42
  extendedchars=true,
  frame=none,
  numbers=left,
  numbersep=5pt,
  numberstyle=\tiny\color{gray},
  commentstyle=\color{gray},
  keywordstyle=\color{OliveGreen},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stepnumber=1,
  tabsize=4,
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\setlength\parskip{1em}
%\setlength{\parindent}{0pt}
\def\arraystretch{2}

\title{
  \vspace{5em}
  Principles of Computer Systems Design \\
  Final Exam
}

\author{%
  \begin{tabular}{l l l}
    Philip Munksgaard & 1989-07-24 & pmunksgaard@gmail.com
  \end{tabular}
}

\date{\today}

\begin{document}

\AddToShipoutPicture*{\put(0,0){\includegraphics*[viewport=0 0 700 600]{ku-farve}}}
\AddToShipoutPicture*{\put(0,602){\includegraphics*[viewport=0 600 700 1600]{ku-farve}}}
\AddToShipoutPicture*{\put(0,0){\includegraphics*{nat-en}}}

\clearpage
\maketitle

\thispagestyle{empty}

\newpage

\fancyhead[LO,RE]{Philip Munksgaard}
\fancyhead[LE,RO]{PCSD, Final Exam \\ \today }
\pagestyle{fancy}

\section*{Theory part}

\subsection*{Question 1 - Proximity}

We wish to examine the performance of an algorithm that merges two big
data sets $R$ and $S$ of $N_1$ and $N_2$ records, respectively, based
on comparison of a $k$ word key. Each record in either data set is $l$
words long. We assume that, by ``merge'', an actual merge-join
operation is the requested operation. We use $M$ to denote the amount
of memory available.

\subsubsection*{CPU Cost}

The data sets are very large, but let us assume that they aren't
larger than $M^2$, such that we can use two-phase merging
algorithms. Now, even though the data sets are (presumably) already in
some kind of database, we cannot reasonably expect them to be
pre-sorted. If that were the case, a simple merge-join would require
at most $(N_1 + N_2) \cdot k$ word comparisons to determine a merge of the
two data sets, as well as $\textrm{max}(N_1, N_2) \cdot (2l - k)$ CPU
operations to write the data, since the merged records have size $2l -
k$. If they aren't sorted we can perform either a merge-join where we
first sort the two inputs, which gives an added cost of $O(N_1 \cdot
log(N_1) + N_2 \cdot log(N_2))$, or a hash-join. The hash-join algorithm
uses a hashing function to compute the hash value for the
key. Assuming it takes $h$ word operations to compute the
hash-function, we need to read and compute the hash function for each
relation, $h \cdot (N_1 + N_2)$; store the relations in buckets and write
those buckets to disk $l(N_1+N_2)$, before finally reading the buckets
from disk and joining them with a one-pass join, $l(N_1 + N_2)$.

If the data sets are so large that we cant apply two-phase merging, we
have to use multi-phase merging. For a given intenger $d$, let us
consider $d$-way merging. For simplicity, we'll concentrate on the
merge-sort algorithm. Here, the difficulty is in sorting the data
sets. The idea is to take the two data sets $R$ and $S$, split them
into a number of groups, $N$, such that we can hold exactly $N+1$
blocks in memory at a time, and recursively sort them. When the groups
are sorted, merge them by reading one block from each group into
memory at at time. Sorting takes $O((N_1 + N_2) \cdot log_N(N_1 +
N_2))$ time, and merging is linear in the number of total records.

However, for these kinds of operations, the time spent by the CPU on
sorting, computing hash functions, merging and the like, is more or
less completely overshadowed by the cost of disk I/O.

\subsubsection*{I/O cost}

%% Analyse the I/O cost of this algorithm. Use B to denote the size of
%% the memory blocks (pages) transferred between the disk and main
%% memory and M to denote the size of main memory; both measured in
%% words.

Now we wish to examine the I/O cost of merging the data sets using a
$d$-phase merging algorithm. We let $B$ denote the page size (distinct
from the $B(\ldots)$ we use to denote the amount of pages something
occupies), and $M$ denote the size of main memory; both measured in
words.

First we need to figure out how many passes are needed to sort the
data sets into $(M-1)/B$ blocks. Using the algorithm described in
section 15.8.2 of \emph{Database Systems: The Complete Book}, we
simply run it with increasing values of $k$, until the result is
smaller than $M$. By letting $d = k$, we know how many phases we need
to go through. Then, we can simply use the calculations from that same
chapter, giving us a total of $(2d-1)(B(R) + B(S))$ disk I/O's, where
$B(R) = lN_1 / B$, meaning that $R$ takes up $lN_1$ words of space,
which is the same as $lN_1 / B$ pages, and analogously for S, just
using $N_2$ instead.

\subsubsection*{Address-translation cost}

%% Analyse the address-translation costs of this algorithm. Use W to
%% denote the size of the address- translation cache measured in words
%% and P to denote the branching factor of the nodes in the page
%% table.

We now wish to analyze the address-translation cost of this
algorithm. We will use $W$ to denote the size of the TLB measured in
entries (the assignment text says words, but in my opinion entries is
a much more meaningful metric, and translation between the two is
trivial, given a specific architecture) and $P$ to denote the
branching factor of the nodes in the page table tree.

\subsection*{Parallelism}

\section*{Programming Part}

\subsection*{Question 1 - Implementation}

%% Overall implementation of OrderManager and ItemSupplier, including
%% the following:

%% - Considering your use of logging, what RPC semantics are
%% effectively implemented between clients and OrderManager or
%% ItemSupplier? What RPC semantics are effectively implemented
%% between OrderManager and ItemSupplier? Explain.

%% - How did you make workflow processing asynchronous at the
%% OrderManager?

The !CertainItemSupplier! class is the basic !ItemSupplier!
implementation. Its constructor is called with a supplier ID and set
of valid item IDs. It is assumed that each !CertainItemSupplier! has a
fixed list of valid item IDs that it can supply. Any requests for
other item IDs will result in an !InvalidItemException! being
thrown. Apart from the !InvalidItemException!, we've also implemented
a number of other subexceptions to !OrderProcessingException!, that
make communication and error handling easier.

The !executeStep! method ensures \emph{all-or-nothing atomicity} by
first making sure that all steps have the correct supplier ID, and
that all item IDs are available at that supplier, and finally that the
amount requested is a positive number (it does not make sense to order
zero or a negative number of items). As the !getOrdersPerItem! method
does not modify any data, we are not concerned with all-or-nothing
atomicity; we just have verify that the item IDs are valid before
querying for the amounts.

The !CertainItemSupplier! class also contains a read-write lock, which
is used to ensure before-or-after atomicity of the operations on the
same item supplier: In !executeStep!, the write-lock is acquired after
verifying the supplier and item IDs; in !getOrdersPerItem! it is
acquired after we've verified the item IDs. This ensures
before-or-after atomicity in !CertainItemSupplier!.

Another approach would have been to have individual read-write locks
for each item ID in the item supplier. However, for simplicity and
ease-of-reasoning, we chose to have just one global lock per item
supplier. We assume that, for this system, !executeStep!, and
therefore modifying updates, will be called much more often than
!getOrdersPerItem! (I feel bad for the item supplier where the
opposite is true), so in either case, the locks acquired will most
likely be exclusive ones. For item suppliers which provide many item
IDs and where most incoming orders only request a few different item,
(say, each order only requests 10 different items, and the supplier
has a thousand different items), we expect a much higher latency using
our method, but if each item supplier only has a small amount of
different items, the benefits of the global-lock approach (that is,
not having to acquire $n$ different locks for $n$ items) far outweigh
the benefits of locking each individual item.

The item supplier is then made available to clients via an RPC
interface that uses HTTP to transfer request and response objects over
the network, which is implemented in the !ItemSupplierHTTPServer! and
related classes. The HTTP server is called by running the
!startServer! method, supplying a port number, a supplier ID and a set
of valid item IDs~\footnote{It is also possible to run the main method
  from the command-line, simply supply port number, supplier ID and a
  number of valid item IDs. } . Clients then use the
!ItemSupplierProxy! class to interface with the item supplier. That
class is called with an address (``http://127.0.0.1:8080'', for
example) and a corresponding supplier ID. This means that each proxy
only handles communication with a single item supplier.

\paragraph{}

The !CertainOrderManager! class is the basic !OrderManager!
implementation. Its constructor is called with a manager ID and a map
containing ItemSuppliers mapped by their IDs.

The !registerOrderWorkflow! method executes the workflow
asynchronously by launching a special !Worker! class in a separate
thread. The !Worker! class is supplied with a !Workflow!, a simple
container class for data pertaining to a work flow, and tries to run
the steps. All steps are continually tried until they succeed, except
if some unrecoverable error occurs, such as requesting an invalid item
or supplier ID, an invalid quantity or a malformed request. When a
step is successful or failed, the thread writes to a shared !Workflow!
object, which can be queried through the !getOrderWorkflowStatus!
method of !CertainOrderManager!. Since we can assume, cf. the
assignment handout, that we always either get a response from the item
supplier, or that the item supplier actually failed, we are thus using
\emph{at-most-once} RPC semantics between the order manager and item
supplier.

\paragraph{}

Durability is achieved by logging all incoming requests to the
!CertainOrderManager! and !CertainItemSupplier! classes. For these
purposes, a !Logger! class has been implemented. It has a !log! method
(which is !synchronized! in order to avoid interleaving outputs) that
is used to serialize an object to XML and write it to a file on
disk. Each !CertainOrderManager! and !CertainItemSupplier! has a
unique ID that is used to name a log file. For the
!CertainItemSupplier!, the log simply consists of all the !OrderStep!
objects that the !executeStep! method has received: The objects are
simply serialized into XML and appended to the log file (which is
flushed before returning). Similarly for the !List<OrderStep>! objects
that !registerOrderWorkflow! receives. This way, durability is
ensured, and recovery is as simple as reading the requests from the
log and executing them. It should be noted that, for the purposes of
this assignment, any already existing log files are deleted when
starting the !Logger!. Adapting the !CertainItemSupplier! and
!CertainOrderManager! classes to check for and recover from
preexisting log files, however, is a trivial matter.

\paragraph{}

%% - How did you handle failures of individual components? In
%% particular, how do you handle failure propagation?

Failure of an item supplier only affects those !OrderStep!s that are
directed towards that item supplier. As described above, the !Worker!
class will simply keep trying to execute the step
indefinitely. Exceptions at the item supplier is communicated through
the !ItemSupplierResponse! class (along with all the other relevant
response information), so the worker always knows if, for example it
has supplied an invalid item ID, or similar.

\subsection*{Question 2}

%% An ItemSupplier executes operations originated at multiple
%% instances of OrderManager as well as local clients. Describe how
%% you ensured atomocity of the operations. Mention the following:

%% Which method did you use to ensure serializability at each item
%% supplier?

%% Argue for the correctness of your method.

%% Argue for the performance of your model.

As discussed above, a simple global-locking mechanism is used in the
!CertainItemSupplier! class to ensure atomicity. As such,
serializability is trivially achieved, as is correctness. However, as
pointed out above, it also has certain drawbacks for some specific use
cases. Our method also ensures that deadlocks cannot occur, although
there is a slight possibility of starvation. However, as described
earlier, in a system like this, we expect far more order registrations
than order overview requests (for instance, we might expect suppliers
to execute !getOrdersPerItem! just a few times per day, in order to
figure out what to produce, package and send, whereas many hundreds or
thousands of customers might issue order registrations each day), so
the exclusive locks wont likely be starved by shared locks.

As mentioned, the alternative would be to have one lock for each item,
which could also quite easily be done, but the benefits of increased
concurrency might be offset by the large overhead of having to acquire
many different locks each time an order request is
issued. We would also have to take deadlocks into account, but they
can be quite easily prevented by first sorting the locks requested.

\subsection*{Question 3}

%% How would you recover from a failure of an OrderManager or an
%% ItemSupplier? For each of the two scenarios, explain necessary
%% interaction with other components to archieve recovery, how you
%% would use the log, why it is sufficient.

Recovery for both the !CertainOrderManager! and the
!CertainItemSupplier! is done by reading the log produced by the
!Logger! class. Since they are the only implementations of their
respective interfaces that actually do any work, they are the only
ones who need to log and recover data. As described above, the output
to the log simply consists of serialized versions of all incoming
requests. Thus, recovering is simply a matter of reading and executing
all the requests from the log in question.

Failures of the !OrderManager! servers should be handled by the
clients. Simply trying another server, or retrying the same server
should suffice. Similarly, and as mentioned above, the !Worker!
threads that !CertainOrderManager! uses to facilitate execution of
steps on item suppliers, simply keeps retrying until they get a
connection to their corresponding server.


\subsection*{Question 4}

%% Describe your high-level strategy to test your
%% implementation. Mention the following:

%% How you tested execution workflows by the OrderManager, considering
%% asynchronicity of execution.

%% How you tested operations were atomic at the ItemSupplier

%% How you tested error conditions and failures of multiple comonents.


\subsection*{Question 5}

%% Design, describe and execute an experiment that shows how your
%% implementation of a single ItemSupplier behaves as concurrency is
%% increased. Mention: Setup, Results. Also figures.

\end{document}
